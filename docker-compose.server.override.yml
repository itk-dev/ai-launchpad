services:
  ollama-proxy:
    image: nginxinc/nginx-unprivileged:alpine
    restart: unless-stopped
    networks:
      - app
    depends_on:
      - ollama
    volumes:
      - ./.docker/proxy/templates:/etc/nginx/templates:ro
      - ./.docker/proxy/nginx.conf:/etc/nginx/nginx.conf:ro
      - .:/app
    environment:
      NGINX_WEB_ROOT: /app/web
      NGINX_PORT: 8080
      MODEL: ollama
      OLLAMA_BACKENDS: "${OLLAMA_BACKENDS:-server ollama:11434 weight=1;}"

  ollama:
    image: ollama/ollama:0.1.44
    networks:
      - app
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "11434"
    environment:
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-12}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-2}
    volumes:
      - ./.docker/data/ollama:/root/.ollama
    # Add support for GPU on the server.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
