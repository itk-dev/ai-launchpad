services:
  ollama-proxy:
    image: haproxytech/haproxy-alpine:3.0
    networks:
      - app
    ports:
      - "80"
    depends_on:
      - ollama
    volumes:
      - ./.docker/proxy/:/usr/local/etc/haproxy:ro

  ollama:
    image: ollama/ollama:0.1.44
    networks:
      - app
    extra_hosts:
      - "host.docker.internal:host-gateway"
    ports:
      - "11434"
    environment:
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-12}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-2}
    volumes:
      - ./.docker/data/ollama:/root/.ollama
    # Add support for GPU on the server.
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              capabilities: [ gpu ]
